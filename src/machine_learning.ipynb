{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53921037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "yolo_folder = '/home/student/Desktop/current_model_ai/obj_train_data'               \n",
    "images_folder = '/home/student/Desktop/current_model_ai/ImagesTotal'                \n",
    "output_folder = '/home/student/Desktop/current_model_ai'                           \n",
    "\n",
    "# === Prepare output directories and clear existing labels ===\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    images_path = os.path.join(output_folder, subset, 'images')\n",
    "    labels_path = os.path.join(output_folder, subset, 'labels')\n",
    "\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    os.makedirs(labels_path, exist_ok=True)\n",
    "\n",
    "    # Clear existing label files\n",
    "    for file in os.listdir(labels_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            os.remove(os.path.join(labels_path, file))\n",
    "\n",
    "# === Collect annotation-image pairs ===\n",
    "data_pairs = []\n",
    "\n",
    "print(\"Searching for matching images and labels...\")\n",
    "for label_file in os.listdir(yolo_folder):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        label_path = os.path.join(yolo_folder, label_file)\n",
    "        \n",
    "        # Match corresponding image\n",
    "        image_found = False\n",
    "        for ext in ['.png', '.jpg', '.jpeg']:\n",
    "            img_name = label_file.replace('.txt', ext)\n",
    "            src_img = os.path.join(images_folder, img_name)\n",
    "            if os.path.exists(src_img):\n",
    "                data_pairs.append((src_img, label_path))\n",
    "                print(f\"Found: {img_name} with {label_file}\")\n",
    "                image_found = True\n",
    "                break\n",
    "        if not image_found:\n",
    "            print(f\"No matching image for label: {label_file}\")\n",
    "\n",
    "print(f\"Total pairs found: {len(data_pairs)}\")\n",
    "\n",
    "# === Shuffle and split data ===\n",
    "random.shuffle(data_pairs)\n",
    "num_images = len(data_pairs)\n",
    "train_split = int(0.7 * num_images)\n",
    "val_split = int(0.9 * num_images)\n",
    "\n",
    "train_data = data_pairs[:train_split]\n",
    "val_data = data_pairs[train_split:val_split]\n",
    "test_data = data_pairs[val_split:]\n",
    "\n",
    "# === Save data ===\n",
    "def save_data(data, subset):\n",
    "    print(f\"Saving {subset} data...\")\n",
    "    saved_count = 0\n",
    "    for img_path, label_path in data:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        label_name = os.path.basename(label_path)\n",
    "\n",
    "        dst_img = os.path.join(output_folder, subset, 'images', img_name)\n",
    "        dst_label = os.path.join(output_folder, subset, 'labels', label_name)\n",
    "\n",
    "        shutil.copy(img_path, dst_img)\n",
    "        shutil.copy(label_path, dst_label)\n",
    "        saved_count += 1\n",
    "\n",
    "    print(f\"{saved_count} images and labels saved in {subset}.\")\n",
    "\n",
    "save_data(train_data, 'train')\n",
    "save_data(val_data, 'val')\n",
    "save_data(test_data, 'test')\n",
    "\n",
    "print(\"Data split and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3735b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_folder = \"/home/student/Desktop/current_model_ai/folder_train\"\n",
    "image_dir = '/home/student/Desktop/current_model_ai/val/images'  # Folder with .jpg images\n",
    "output_fp_dir = 'false_positive_visuals'\n",
    "os.makedirs(output_fp_dir, exist_ok=True)\n",
    "# Remove the folder if it exists\n",
    "if os.path.exists(train_folder):\n",
    "    shutil.rmtree(train_folder)\n",
    "\n",
    "# Load the model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# === Training ===\n",
    "model.train(\n",
    "    data='/home/student/Desktop/current_model_ai/data.yaml',\n",
    "    epochs=30,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    project='/home/student/Desktop/current_model_ai/folder_train',\n",
    "    name='folds_retrain',\n",
    "    shear=2.5,\n",
    "    scale=0.1,\n",
    "    translate=0.0,\n",
    "    degrees=0.0,\n",
    "    conf=0.3,\n",
    "    augment=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on dataset\n",
    "predict_folder = \"/home/student/Desktop/current_model_ai/PredictedImages\"\n",
    "test_images = \"/home/student/Desktop/current_model_ai/test/images\"\n",
    "gt_labels = \"/home/student/Desktop/current_model_ai/test/labels\"\n",
    "\n",
    "# === Clean old predictions ===\n",
    "if os.path.exists(predict_folder):\n",
    "    shutil.rmtree(predict_folder)\n",
    "\n",
    "# === Load trained model ===\n",
    "model = YOLO('/home/student/Desktop/current_model_ai/folder_train/folds_retrain/weights/best.pt')\n",
    "\n",
    "# === Run predictions ===\n",
    "results = model.predict(\n",
    "    source=test_images,\n",
    "    conf=0.4,\n",
    "    iou=0.4,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    project='/home/student/Desktop/current_model_ai',\n",
    "    name='PredictedImages'\n",
    ")\n",
    "\n",
    "# === Paths after prediction ===\n",
    "pred_labels = os.path.join(predict_folder, 'labels')\n",
    "\n",
    "# === Evaluate confusion matrix ===\n",
    "y_true = []\n",
    "y_pred = []\n",
    "background_images = []\n",
    "\n",
    "print(\"\\nEvaluating confusion matrix:\")\n",
    "\n",
    "for filename in os.listdir(test_images):\n",
    "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    gt_label_file = os.path.join(gt_labels, name + '.txt')\n",
    "    pred_label_file = os.path.join(pred_labels, name + '.txt')\n",
    "\n",
    "    gt_has_label = os.path.exists(gt_label_file) and os.path.getsize(gt_label_file) > 0\n",
    "    pred_has_label = os.path.exists(pred_label_file) and os.path.getsize(pred_label_file) > 0\n",
    "\n",
    "    if not pred_has_label:\n",
    "        background_images.append(filename)\n",
    "\n",
    "    # Labels: 1 = V (fold), 0 = background\n",
    "    y_true.append(1 if gt_has_label else 0)\n",
    "    y_pred.append(1 if pred_has_label else 0)\n",
    "\n",
    "# === Generate confusion matrix ===\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "labels = ['V', 'background']\n",
    "\n",
    "# === Print background images ===\n",
    "print(\"\\nImages predicted as background (no detections):\")\n",
    "for bg_img in background_images:\n",
    "    print(\" -\", bg_img)\n",
    "\n",
    "print(f\"\\nTotal background predictions: {len(background_images)}\")\n",
    "\n",
    "# === Compute percentages ===\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        count = cm[i, j]\n",
    "        perc = cm_percent[i, j]\n",
    "        annot[i, j] = f\"{count}\\n({perc:.1f}%)\"\n",
    "\n",
    "# === Plot confusion matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.ylabel(\"Predicted Label\")\n",
    "plt.title(\"Confusion Matrix with Percentages\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save confusion matrix ===\n",
    "output_path = os.path.join(predict_folder, 'confusion_matrix_percent.png')\n",
    "plt.savefig(output_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion matrix with percentages saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7a418",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/student/Desktop/current_model_ai/training_results_v2/model_selection_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Clean project folder\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(project_root):\n\u001b[0;32m      7\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(project_root)\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(project_root, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Model selection\n",
    "data_yaml = '/home/student/Desktop/current_model_ai/data.yaml'\n",
    "project_root = '/home/student/Desktop/current_model_ai/training_results_v2'\n",
    "csv_path = '/home/student/Desktop/current_model_ai/training_results_v2/model_selection_metrics.csv'\n",
    "\n",
    "# Clean project folder\n",
    "if os.path.exists(project_root):\n",
    "    shutil.rmtree(project_root)\n",
    "\n",
    "os.makedirs(project_root, exist_ok=True)\n",
    "\n",
    "# Phase 1: Model selection\n",
    "models = ['yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt']\n",
    "model_metrics = {}\n",
    "\n",
    "for model_name in models:\n",
    "    name = os.path.splitext(model_name)[0] + '_baseline'\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model = YOLO(model_name)\n",
    "    model.train(data=data_yaml, epochs=30, imgsz=640, batch=8,\n",
    "                name=name, project=project_root, patience=10, verbose=False)\n",
    "\n",
    "    # Evaluate\n",
    "    results = model.val(data=data_yaml)\n",
    "\n",
    "    # Extract metrics\n",
    "    metrics = {\n",
    "        'Box(P)': float(results.box.p),\n",
    "        'Recall': float(results.box.r),\n",
    "        'mAP50': float(results.box.map50),\n",
    "        'mAP50-95': float(results.box.map)\n",
    "    }\n",
    "    model_metrics[model_name] = metrics\n",
    "\n",
    "# Write metrics to CSV\n",
    "\n",
    "with open(csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Header\n",
    "    writer.writerow(['Model', 'Box(P)', 'Recall', 'mAP50', 'mAP50-95'])\n",
    "    # Data rows\n",
    "    for model_name, metrics in model_metrics.items():\n",
    "        writer.writerow([model_name] + list(metrics.values()))\n",
    "\n",
    "# Identify best model\n",
    "best_model = max(model_metrics, key=lambda m: model_metrics[m]['mAP50'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266ba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️ Phase 2: Epoch + Batch optimization\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/student/Desktop/current_model_ai/training_results_v2/epoch_batch_selection_metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m⚙️ Phase 2: Epoch + Batch optimization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create CSV and write header\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m     15\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m     16\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch Size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox(P)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@0.5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@0.5:0.95\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\joaki\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/student/Desktop/current_model_ai/training_results_v2/epoch_batch_selection_metrics.csv'"
     ]
    }
   ],
   "source": [
    "# Epoch + Batch optimization\n",
    "project_root = '/home/student/Desktop/current_model_ai/training_results'\n",
    "data_yaml = '/home/student/Desktop/current_model_ai/data.yaml'\n",
    "best_model = 'yolo11n.pt'\n",
    "\n",
    "# Phase 2: Epoch + Batch optimization\n",
    "epoch_values = [30, 50, 70, 100, 150]\n",
    "batch_values = [4, 8, 16, 32]\n",
    "epoch_batch_scores = []\n",
    "csv_path = '/home/student/Desktop/current_model_ai/training_results_v2/epoch_batch_selection_metrics.csv'\n",
    "\n",
    "# Create CSV and write header\n",
    "with open(csv_path, mode='w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Run Name', 'Epochs', 'Batch Size', 'Box(P)', 'Recall', 'mAP@0.5', 'mAP@0.5:0.95'])\n",
    "\n",
    "    for epochs, batch in itertools.product(epoch_values, batch_values):\n",
    "        run_name = f'{os.path.splitext(best_model)[0]}_e{epochs}_b{batch}'\n",
    "        run_dir = os.path.join(project_root, run_name)\n",
    "        os.makedirs(run_dir, exist_ok=True)  # <-- Add this line\n",
    "        print(f\"Training {run_name}...\")\n",
    "\n",
    "        model = YOLO(best_model)\n",
    "        model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=640,\n",
    "            batch=batch,\n",
    "            name=run_name,\n",
    "            project=project_root,\n",
    "            patience=10,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        results = model.val(data=data_yaml)\n",
    "\n",
    "        metrics = {\n",
    "            'Box(P)': float(results.box.p),\n",
    "            'Recall': float(results.box.r),\n",
    "            'mAP50': float(results.box.map50),\n",
    "            'mAP50-95': float(results.box.map)\n",
    "        }\n",
    "\n",
    "        # Save for best config selection\n",
    "        epoch_batch_scores.append((epochs, batch, metrics['mAP50']))\n",
    "\n",
    "        # Write to CSV\n",
    "        writer.writerow([\n",
    "            run_name, epochs, batch,\n",
    "            metrics['Box(P)'], metrics['Recall'],\n",
    "            metrics['mAP50'], metrics['mAP50-95']\n",
    "        ])\n",
    "\n",
    "\n",
    "# Pick best configuration\n",
    "best_epochs, best_batch, _ = max(epoch_batch_scores, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid optimization for augmentations\n",
    "project_root = '/home/student/Desktop/current_model_ai/training_results'\n",
    "data_yaml = '/home/student/Desktop/current_model_ai/data.yaml'\n",
    "best_model = 'yolo11n.pt'\n",
    "\n",
    "# Phase 3: Grid Search on augmentations\n",
    "shear_vals = [0.0, 2.5, 5.0, 7.5]\n",
    "scale_vals = [0.0, 0.03, 0.06, 0.1]\n",
    "translate_vals = [0.0, 0.03, 0.06, 0.1]\n",
    "degrees_vals = [0.0, 5.0, 10.0, 15.0]\n",
    "param_grid = list(itertools.product(shear_vals, scale_vals, translate_vals, degrees_vals))\n",
    "\n",
    "# Find index to start from: INCLUDE this config\n",
    "start_config = (2.5, 0.06, 0.06, 15.0)\n",
    "start_index = next(i for i, params in enumerate(param_grid) if params == start_config)\n",
    "\n",
    "# Slice param_grid from start_index onward\n",
    "param_grid = param_grid[start_index:]\n",
    "grid_results = []\n",
    "\n",
    "for i, (shear, scale, translate, degrees) in enumerate(param_grid, start=start_index):\n",
    "    run_name = f'grid_shear{shear}_scale{scale}_trans{translate}_deg{degrees}'\n",
    "    print(f\"Training {run_name} ({i+1}/{len(shear_vals)*len(scale_vals)*len(translate_vals)*len(degrees_vals)})...\")\n",
    "\n",
    "    model = YOLO(best_model)\n",
    "    model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=30,\n",
    "        batch=8,\n",
    "        imgsz=640,\n",
    "        name=run_name,\n",
    "        project=project_root,\n",
    "        shear=shear,\n",
    "        scale=scale,\n",
    "        translate=translate,\n",
    "        degrees=degrees,\n",
    "        augment=True,\n",
    "        patience=10,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results = model.val(data=data_yaml)\n",
    "\n",
    "    metrics = {\n",
    "        'Box(P)': float(results.box.p),\n",
    "        'Recall': float(results.box.r),\n",
    "        'mAP50': float(results.box.map50),\n",
    "        'mAP50-95': float(results.box.map)\n",
    "    }\n",
    "\n",
    "    grid_results.append({\n",
    "        'Run': run_name,\n",
    "        'Shear': shear,\n",
    "        'Scale': scale,\n",
    "        'Translate': translate,\n",
    "        'Degrees': degrees,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "# Append results to CSV\n",
    "csv_path = '/home/student/Desktop/current_model_ai/training_results_v2/augmentation_results.csv'\n",
    "write_header = not os.path.exists(csv_path)\n",
    "with open(csv_path, mode='a', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\n",
    "        'Run', 'Shear', 'Scale', 'Translate', 'Degrees',\n",
    "        'Box(P)', 'Recall', 'mAP50', 'mAP50-95'\n",
    "    ])\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerows(grid_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
